# Digital Omnibus - Common Themes Analysis

Generated: 2025-11-25 21:40

Based on 416 analysed responses

## Summary Statistics

- Total responses analysed: 416
- Pro-protection responses: 93
- Pro-simplification responses: 209
- Responses mentioning PETs: 15
- Responses discussing pseudonymisation issues: 13
- Responses discussing legitimate interest: 22

---
## Common Themes: DEFENDING Privacy Safeguards

### 1. Fundamental Rights Must Not Be Compromised

**Summary**: Simplification efforts should not weaken or undermine fundamental rights protections, including privacy, data protection, equality, and cultural rights. Any regulatory changes must preserve the integrity of existing rights frameworks.

**Organisations making this argument** (11):
- Ada Lovelace Institute
- European network of equality bodies (Equinet)
- noyb
- Access Now Europe
- Anonymous (LTU)
- AI Accountability Lab (AIAL), Trinity College Dublin
- Culture Action Europe
- European Network Against Racism (ENAR)
- STM
- BEUC - The European Consumer Organisation
- ...and 1 more

### 2. Evidence-Based Approach Required

**Summary**: Changes to regulations must be based on concrete evidence of real-world impacts and costs. The burden of proof should be on industry to demonstrate actual compliance costs, and evidence should be made publicly available for transparency.

**Organisations making this argument** (3):
- Ada Lovelace Institute
- Orla Harris
- noyb

### 3. Premature to Amend Before Full Implementation

**Summary**: It is too early to simplify or amend digital regulations like the AI Act, GDPR, and ePrivacy Directive when implementation experience is still lacking and provisions are only now entering into force.

**Organisations making this argument** (5):
- European network of equality bodies (Equinet)
- noyb
- Xavier Desire Andre TRACOL
- European Network Against Racism (ENAR)
- Euroconsumers

### 4. Consent and User Control Must Be Preserved

**Summary**: User consent remains essential for data processing and tracking. Cookie consent mechanisms, while needing improvement, are a necessary translation of consent principles online. Individual choice over personal data must be maintained.

**Organisations making this argument** (5):
- Orla Harris
- Anonymous (FRA)
- Anonymous (LTU)
- INRIA and Utrecht University
- BEUC - The European Consumer Organisation

### 5. Technical Solutions for Cookie Fatigue

**Summary**: Cookie fatigue should be addressed through technical standardisation and browser-based consent management systems, not through weakening consent requirements. Dark patterns in cookie banners manipulate users and undermine autonomous decision-making.

**Organisations making this argument** (4):
- Anonymous (FRA)
- noyb
- INRIA and Utrecht University
- Euroconsumers

### 6. Simplification Benefits Business Over Citizens

**Summary**: Reducing compliance costs for companies will inevitably weaken protections for citizens. The Commission is prioritising business interests over consumer protection and community perspectives.

**Organisations making this argument** (4):
- Orla Harris
- noyb
- Access Now Europe
- European Network Against Racism (ENAR)

### 7. Regulatory Coherence Without Deregulation

**Summary**: Simplification should mean clearer guidance, better alignment between regulations, and easier compliance - not weaker rules or deregulation. Clarity should be achieved through guidance rather than legislative amendments.

**Organisations making this argument** (5):
- European network of equality bodies (Equinet)
- STM
- BEUC - The European Consumer Organisation
- Eurosmart
- Filiera Italia

### 8. Protection of Vulnerable Groups

**Summary**: Digital simplification must not reduce rights or protections for vulnerable groups including persons with disabilities. Universal accessibility and design for all must be core principles, and AI systems pose risks of algorithmic bias and discrimination.

**Organisations making this argument** (3):
- CERMI
- AI Accountability Lab (AIAL), Trinity College Dublin
- European Network Against Racism (ENAR)

### 9. Comprehensive Tracking Coverage Needed

**Summary**: Current regulations must cover all tracking technologies including cookies, fingerprinting, server-side tracking, and new identifier-based methods. Server-side tagging obscures tracking detection and browser fingerprinting creates regulatory grey zones.

**Organisations making this argument** (2):
- Anonymous (FRA)
- INRIA and Utrecht University

### 10. AI Risks Require Strong Safeguards

**Summary**: AI adoption measures risk creating new forms of surveillance, control, and violations at scale. The AI Act was specifically designed to address harms from high-risk AI systems and should not be undermined. Proper balance of responsibilities in medical AI and other sectors must be preserved.

**Organisations making this argument** (5):
- AI Accountability Lab (AIAL), Trinity College Dublin
- European Society of Radiology
- CERMI
- Euroconsumers
- Filiera Italia

---
## Common Themes: SUPPORTING Simplification/Loosening

### 1. Regulatory Overlap and Fragmentation

**Summary**: Current EU digital regulations (GDPR, AI Act, Data Act, NIS2, CRA, DORA, etc.) create overlapping, duplicative, and sometimes conflicting requirements. Respondents call for better alignment, clearer separation of objectives, and elimination of redundant obligations across these frameworks.

**Organisations making this argument** (10):
- Dedalus S.p.A.
- Meta Platforms Ireland Limited
- Snap Inc.
- Siemens Healthineers AG
- Prosus Group
- Lenovo
- Confederation of Swedish Enterprise
- European Games Developer Federation (EGDF)
- Schaeffler AG
- Dutch Startup Association

### 2. Harmonised Incident and Breach Reporting

**Summary**: Multiple regulations impose separate incident reporting requirements with different timelines, formats, and portals. Respondents advocate for a centralized EU-level reporting mechanism with standardized identifiers and coordinated procedures across GDPR, NIS2, DORA, CRA, and other frameworks.

**Organisations making this argument** (5):
- Dedalus S.p.A.
- Snap Inc.
- Relyens Mutual Insurance
- Schaeffler AG
- Prosus Group

### 3. Excessive Administrative Burden

**Summary**: Current compliance requirements impose disproportionate administrative costs, particularly affecting SMEs and innovation. Respondents urge reduction of documentation requirements, streamlined processes, and removal of obligations that do not meaningfully increase consumer or societal protection.

**Organisations making this argument** (8):
- Meta Platforms Ireland Limited
- Siemens Healthineers AG
- Prosus Group
- European Entrepreneurs CEA-PME
- Confederation of Swedish Enterprise
- Too Good To Go
- Software & Information Industry Association (SIIA)
- European Games Developer Federation (EGDF)

### 4. Inconsistent Cross-Border Implementation

**Summary**: EU regulations are interpreted and applied differently across Member States, creating legal uncertainty and uneven playing fields. Germany's 16 regional GDPR interpretations is cited as a specific example. Respondents call for uniform application and harmonised guidance across all Member States.

**Organisations making this argument** (3):
- European Entrepreneurs CEA-PME
- Confederation of Swedish Enterprise
- European Games Developer Federation (EGDF)

### 5. Sector-Specific Regulatory Approaches

**Summary**: Horizontal regulations fail to account for specific sectoral needs and existing frameworks. Respondents in healthcare, medical technology, automotive, and wind energy argue for sector-specific rules that recognize existing compliance regimes (e.g., MDR/IVDR, vehicle type approval) and operational realities.

**Organisations making this argument** (5):
- Dedalus S.p.A.
- Siemens Healthineers AG
- Relyens Mutual Insurance
- Schaeffler AG
- WindEurope

### 6. AI Act Clarification and Proportionality

**Summary**: The AI Act's high-risk classifications and compliance requirements are overly broad, capturing AI-assisted tools that should be exempt. Respondents seek clearer distinctions between AI-determined and AI-assisted outcomes, better alignment with GDPR, and proportionate requirements that don't stifle innovation.

**Organisations making this argument** (6):
- Dedalus S.p.A.
- Siemens Healthineers AG
- Prosus Group
- Lenovo
- Software & Information Industry Association (SIIA)
- Schaeffler AG

### 7. Data Act Implementation Challenges

**Summary**: Data Act requirements create practical compliance problems, particularly around consent mechanisms for industrial data, conflicts with existing contractual arrangements, and protection of trade secrets. Respondents argue for standardised consent categories, clearer pathways for critical infrastructure, and alignment with GDPR.

**Organisations making this argument** (3):
- WindEurope
- Schaeffler AG
- Confederation of Swedish Enterprise

### 8. Competitiveness and Innovation Concerns

**Summary**: Overly complex and burdensome regulations are harming European competitiveness and innovation capacity relative to other global markets. Respondents urge prioritising speed, scale, and a more business-friendly environment to enable European companies to compete globally.

**Organisations making this argument** (5):
- Meta Platforms Ireland Limited
- Prosus Group
- European Entrepreneurs CEA-PME
- Software & Information Industry Association (SIIA)
- Too Good To Go

### 9. Stabilise Before Adding New Rules

**Summary**: Before introducing new regulatory obligations, the Commission should allow existing frameworks to stabilise, conduct thorough ex-post impact assessments, and evaluate real-world effects. Respondents call for a moratorium on new rules until current ones are properly implemented and assessed.

**Organisations making this argument** (3):
- LA POSTE
- Confederation of Swedish Enterprise
- Snap Inc

### 10. Cookie and ePrivacy Reform

**Summary**: Current ePrivacy directive cookie consent rules are outdated, incompatible with modern digital practices, and should be reformed to align better with GDPR. The binary categorisation of cookies as necessary or unnecessary is no longer appropriate.

**Organisations making this argument** (1):
- The Finnish Media Federation, Finnmedia

---
## Detailed: Privacy-Enhancing Technologies Mentions

### The European Crypto Initiative (EUCI) (BEL)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088863_en)

They advocate for recognising 'functional anonymisation' where cryptographic safeguards make re-identification not reasonably likely, suggesting PETs should be used as a basis for lighter regulatory treatment.

> "recognising functional anonymisation where cryptographic safeguards make re-identification not reasonably likely"

### Skyscanner (GBR)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088763_en)

Skyscanner mentions that the regulatory framework should incentivise the use of privacy-enhancing solutions, suggesting PETs could enable easier data collection where privacy impacts are low.

> "incentivises the use of privacy-enhancing solutions, and allows organisations to collect important information more easily where privacy impacts are low"

### European Tech Alliance (BEL)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088667_en)

EUTA proposes that Privacy-Enhancing Technologies (PETs) should be explicitly recognized as a proportionate safeguard for reading and storing low-sensitivity data under the modernized ePrivacy framework. They emphasize PETs must be deployable at scale, accessible throughout the value chain, made available free of charge, and governed by EU-level standards to ensure interoperability and prevent market dominance by any single provider.

> "The 'modernization' of the rules on cookies expressed in the call for evidence should also explicitly recognise Privacy-Enhancing Technologies (PETs) as a proportionate safeguard for the reading and storing of data (low-sensitivity data). Embedding PETs in this way would ensure that data use remains privacy-preserving, interoperable, and consistent with EU standards, while avoiding undue reliance on any single provider."

### Agilitation (FRA)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088147_en)

They explicitly request that Consent Management Platforms (CMPs) be recognized as privacy-enhancing technologies (PETs) that embody EU digital sovereignty objectives and help SMEs comply with EU law.

> "recognise CMPs as privacy-enhancing technologies (PETs) that embody the EU's digital sovereignty objectives and enable SMEs to comply with EU law efficiently and affordably"

### European Publishers Council (BEL)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088597_en)

They argue that current outdated rules are actually stifling innovation in privacy-enhancing technologies, as companies focus on navigating consent requirements rather than investing in privacy-by-design solutions. They specifically mention data clean rooms and contextual targeting as examples of PETs that could offer both privacy and sustainable business models.

> "these outdated rules are stifling innovation in privacy-enhancing technologies, as companies focus on navigating complex consent requirements rather than investing in new privacy-by-design solutions such as secure data clean rooms or contextual targeting models that could offer both high privacy standards and sustainable business models"

### Connect Europe (BEL)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088566_en)

They mention pseudonymisation and anonymisation as safeguards that should be applied when processing personal data for AI training, as part of a set of guardrails including 'early pseudonymisation or anonymisation' and propose guidelines including 'Pseudonymisation and minimisation by design'.

> "Such processing of personal data for the training of AI systems and models would include clear guardrails, such as the exclusion of sensitive data sources, limitations of data categories, early pseudonymisation or anonymisation, transparency towards data subjects, and a risk-based evaluation of relevant safeguards"

### Panasonic Europe B.V. (JPN)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088392_en)

Panasonic advocates for a consent-free basis for first-party measurement that specifically uses privacy-enhancing techniques, suggesting PETs as a condition for allowing certain data processing without consent.

> "a narrow consentfree basis for firstparty measurement using privacyenhancing techniques"

### Rigo WENNING (DEU)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33087954_en)

Advocates for machine-readable privacy signals and their secure recording as a mechanism to enhance and simplify the privacy experience, building on the approach established in Art 21(5) GDPR.

> "Legally valid signals and their secure recording are a precondition to enhance and simplify the privacy experience."

### ITI - Information Technology Industry Council (BEL)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33087752_en)

ITI recommends that the EU 'strongly encourage and incentivize the use of Privacy-Enhancing Technologies (PETs) to minimize privacy risks when processing sensitive categories of personal data for AI.' They also mention pseudonymization, anonymization, and synthetic data as privacy-preserving techniques that should be recognized in guidance.

> "The EU should strongly encourage and incentivize the use of Privacy-Enhancing Technologies (PETs) to minimize privacy risks when processing sensitive categories of personal data for AI."

### Bitkom e.V. (DEU)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33087277_en)

Bitkom discusses pseudonymization and anonymization as technical measures to enable data sharing under the Data Act while protecting personal data. They propose that mixed datasets should not be treated as personal data if pseudonymized according to recognized standards and re-identification by unauthorized third parties can be effectively excluded. They also mention encryption as a safeguard for AI data processing.

> "By employing pseudonymization or anonymization techniques, it can be ensured that no directly identifiable personal information is disclosed when data is shared."

### Robin Berjon (FRA)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33085950_en)

Extensively discusses Global Privacy Control (GPC) as a privacy-enhancing technical signal that automates user privacy preferences. GPC is a browser-based automated signal that creates single-controllership situations, reducing tracking across the internet. The author co-developed GPC and deployed it at The New York Times.

> "Developing and deploying the Global Privacy Control (GPC) as a technical system to reduce compliance costs, improve user experience, and improve the business position of media publishers with respect to tech monopolies and advertising intermediaries."

### Anonymous (CZE)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33083448_en)

Advocates for Global Privacy Control (GPC), a browser-based privacy signal technology that would replace individual website cookie consent with a universal privacy preference mechanism.

> "Použití globálních řešení založených na prohlížeči - Global Privacy Control (viz https://globalprivacycontrol.org/ a specifikace na https://w3c.github.io/gpc/) by to vyřešilo."

### PII Guard (DNK)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33082766_en)

They propose using Privacy-Enhancing Technologies (PETs) as a condition for enabling legitimate-interest processing for low-risk purposes, and advocate for mandatory PET protection for secondary data copies with a 'protection-for-lifetime' principle.

> "allow legitimate-interest processing for low-risk purposes (e.g. analytics, fraud detection, security) when strong Privacy-Enhancing Technologies (PETs) are applied"

### VLASTIMIL ZÍMA (CZE)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33072894_en)

Discusses browser-based privacy solutions including plugins (Consent-O-Matic, Ghostery) and standardized privacy signals (Do-Not-Track, Global Privacy Control) as technical mechanisms to protect user privacy and manage consent.

> "I strongly support a browser-based solution. Years ago, Mozilla introduced the Do-Not-Track mechanism, which was intended to give users more control over their data. Unfortunately, it was not widely respected by websites. Today, the Do-Not-Track mechanism has been replaced by Global Privacy Control"

### Martin Slíva (CZE)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33071283_en)

Explicitly discusses pseudonymisation as a technique for processing personal data including special categories, positioning it as a safeguard that should enable broader data processing for regulatory compliance purposes.

> "Zpracování osobních údajů, včetně zvláštních kategorií osobních údajů, ve formě pseudonymizovaných souborů dat je nezbytné pro zajištění souladu"

---
## Detailed: Pseudonymisation/De-identification Concerns

### Anonymous (FRA)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33089165_en)

The respondents argue that the binary distinction between personal and non-personal data in GDPR Article 4.1 is outdated due to browser fingerprinting research. They identify a 'grey zone' of technical data (HTTP headers, JavaScript APIs, CPU/GPU benchmarks) that can identify individuals through their devices even though such data might be considered 'purely technical' and non-personal. This effectively critiques the assumption that technical/pseudonymous data cannot be used for identification.

> "We argue that this distinction is no longer up to date with the state-of-the-art of research in the domain of browser fingerprinting: a grey zone of data that can reveal personal information exists between the two extremes of personal and non personal data."

### Schaeffler AG (DEU)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088950_en)

Schaeffler argues that companies circumvent Data Act requirements by mixing generated data with personal data to invoke GDPR protections, and that lack of 'GDPR-proof pseudonymization pathways' creates barriers to vehicle data access. They want data access rights to prevail when personal data has been anonymized or pseudonymized.

> "To prevent circumvention, it is important to provide clarification in instances, where there is the question of whether the GDPR takes precedence over the Data Act. In this particular case, the right to access data should prevail, when personal data has been anonymized or pseudonymized."

### The European Crypto Initiative (EUCI) (BEL)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088863_en)

They implicitly argue that current anonymisation/pseudonymisation standards are too strict or unclear, advocating for a new concept of 'functional anonymisation' based on cryptographic measures rather than absolute impossibility of re-identification.

> "recognising functional anonymisation where cryptographic safeguards make re-identification not reasonably likely"

### Alliance Digitale (FRA)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088807_en)

They argue that pseudonymised data should be explicitly excluded from Article 11 obligations, suggesting that current rules applying to pseudonymised data are burdensome and unclear.

> "explicitly exclude pseudonymised data from Article 11 obligations to create a clear and predictable standard for all stakeholders"

### ORANGE (FRA)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088583_en)

Orange argues that the Data Act's concept of 'user's non-personal data' is incoherent because if data can be indirectly linked to individuals through additional identifiers, it constitutes pseudonymized data under GDPR, making the distinction between personal and non-personal data misleading.

> "Conversely, if the data can be indirectly linked to individuals through additional identifiers, they constitute pseudonymized data and should be treated as personal data under the GDPR, rendering the term 'non-personal data' inaccurate."

### The Danish Chamber of Commerce (DNK)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088369_en)

They argue that pseudonymised information should be usable without requiring prior consent for cookies and tracking technologies, suggesting the current consent requirements are overly burdensome.

> "it should be permissible to use simple personal data, such as IP addresses, as well as pseudonymised information, without the requirement for prior consent"

### CLEPA (BEL)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33088318_en)

CLEPA argues that data holders may circumvent data-sharing obligations by categorising operational data as 'personal' and invoking GDPR, and recommends that data-sharing obligations should prevail where data has been effectively anonymised or pseudonymised. They also call for GDPR-compliant pseudonymisation procedures to prevent undue restrictions on data access.

> "Prevent circumvention by specifying that data-sharing obligations prevail where the personal data in question has been effectively anonymised or pseudonymised."

### Verband der Automobilindustrie e.V.  (DEU)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33087761_en)

VDA proposes 'GDPR-proof pseudonymization pathways' for vehicle data to address the problem that data access is currently refused solely because personal data is present, particularly affecting fleets and shared vehicles where personal data is co-mingled with telemetry.

> "Mandate a portable, machine-readable proof-of-consent/authorization standard for vehicle data/functions under the Data Act, with clear role allocation (holder/recipient/processor) and GDPR-proof pseudonymization pathways so that access cannot be refused solely because personal data is present."

### ITI - Information Technology Industry Council (BEL)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33087752_en)

ITI argues that pseudonymized data receives insufficient regulatory recognition compared to anonymized data, creating a disincentive for companies to use privacy-enhancing techniques. They advocate for treating pseudonymized data more flexibly, closer to the approach taken with anonymous data, and introducing a more realistic standard for likelihood of re-identification.

> "Pseudonymized data is a key example. While it significantly limits the ability to link data to individuals, it is afforded little regulatory recognition compared to anonymized data. As a result, the framework provides insufficient incentives for companies to use privacy-enhancing techniques, even where they meaningfully reduce risks to individuals."

### Finnish Food and Drink Industries´ Federation (ETL)  (FIN)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33087415_en)

They argue that the assessment of what constitutes sufficient pseudonymisation is currently unstructured and unclear, implying this creates compliance difficulties.

> "The assessment of sufficient pseudonymisation remains unstructured and unclear."

### Bitkom e.V. (DEU)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33087277_en)

Bitkom identifies a fundamental problem: pseudonymized data is still considered personal data under GDPR (Recital 26), which creates conflicts with the Data Act's data sharing requirements. They note the DORA Regulation creates technical conflict by permitting pseudonymized data storage in non-production environments while GDPR treats it as personal data. They call for clear, legally binding requirements for pseudonymization and anonymization.

> "However, it should be noted that the use of pseudonymous data does not exempt data from the obligations under the Data Act. Therefore, the proposal is: mixed datasets should not be treated as personal data if the personal data has been pseudonymized according to recognized standards and re-identification by unauthorized third parties can be effectively excluded."

### Salesforce, Inc.  (USA)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33087066_en)

Salesforce argues that the GDPR's high bar for true anonymization is virtually impossible to prove, especially given modern AI capabilities. They contend this causes data intended for AI analysis to be regulated as personal data even when minimal re-identification risk exists, unnecessarily triggering full compliance requirements for low-risk applications.

> "Because true anonymization is virtually impossible to prove, data intended for AI analysis is often regulated as personal data even if minimal risk exists. This risks unnecessarily triggering the full compliance regime (DPIAs, consent, rights of erasure) for low-risk applications."

### Martin Slíva (CZE)
[View submission](https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14855-Simplification-digital-package-and-omnibus/F33071283_en)

Implicitly addresses the problem that current GDPR framework lacks explicit legal basis for processing pseudonymised data for regulatory compliance, particularly for healthcare AI systems requiring conformity assessment and post-market clinical follow-up.
